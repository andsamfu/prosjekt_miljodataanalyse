# src/ â€“ Kildekode

Denne mappen inneholder all kildekode knyttet til prosjektets kjernelogikk. Koden er delt opp i tre hovedmoduler:

- `data_collection/` â€“ Henter inn miljÃ¸data fra Ã¥pne API-er
- `data_cleaning/` â€“ Renser og strukturerer data for analyse
- `graph/` â€“ Lager visualiseringer basert pÃ¥ analyserte data

Funksjonene her importeres og brukes i hovednotebooken, slik at sluttbrukeren kan fokusere pÃ¥ Ã¥ utforske og analysere data â€“ uten Ã¥ mÃ¥tte forholde seg til store mengder kode.

---

## ğŸ“¦ `data_collection/` â€“ Datainnsamling

Denne modulen samler inn miljÃ¸data fra to Ã¥pne API-er: Meteorologisk institutts **Frost API** og **NILU API** for luftkvalitet. Dataene hentes med Python og lagres i `data/raw/` som `.json`- eller `.db`-filer.

---

### ğŸŒ¦ï¸ Frost API (Meteorologisk institutt)

Vi bruker Frost API til Ã¥ hente vÃ¦rdata for Trondheim i perioden 2010â€“2019:

- Gjennomsnittlig lufttemperatur (daglig)
- Total nedbÃ¸r (daglig)
- Gjennomsnittlig vindstyrke (daglig)

FremgangsmÃ¥te:
- Henter nÃ¦rmeste vÃ¦rstasjon basert pÃ¥ geografiske koordinater (Trondheim sentrum)
- Henter observasjoner for valgt tidsperiode via `observations`-endepunktet
- Strukturerer dataene i en DataFrame og aggregerer dem med SQL-spÃ¸rring
- Lagrer resultatet i en SQLite-database (`data/raw/raw_api_frost_weather_trondheim_2010_to_2019.db`)

---

### ğŸŒ«ï¸ NILU API (Norsk institutt for luftforskning)

Vi bruker NILU API for Ã¥ hente luftkvalitetsdata for Trondheim for perioden 2010â€“2024.

Komponentene inkluderer blant annet:
- PM2.5
- PM10
- NOâ‚‚, Oâ‚ƒ m.m.

FremgangsmÃ¥te:
- Bruker `stats/day`-endepunktet med koordinater og radius
- Henter data for alle tilgjengelige komponenter
- Lagrer resultatet som `.json` i `data/raw/raw_api_nilu_air_quality_trondheim_2010_to_2024.json`

---

### ğŸ” NÃ¸kkelhÃ¥ndtering

- Frost API krever klient-ID (API-nÃ¸kkel), som lastes inn fra `.env`
- NILU API er offentlig og krever ingen autentisering

---

## ğŸ§¹ `data_cleaning/` â€“ Datarensing

Etter at rÃ¥data er hentet, behandles de i `data_cleaning/` for Ã¥ sikre at de er klare til analyse og visualisering.

Rensetrinnene for NILU-data inkluderer:
- Konvertering av `dateTime` til riktig tidsformat
- Pivoterer mÃ¥linger slik at hver luftkomponent blir en kolonne
- Fjerner irrelevante komponenter (f.eks. benzo(a)pyrene)
- Fyller inn manglende dager med tomme rader
- Bruker lineÃ¦r interpolasjon for Ã¥ estimere manglende verdier
- Lager ekstra kolonner som viser hvilke verdier som er generert (interpolert)
- Runder av verdier og fjerner duplikater
- Erstatter negative verdier med 0 for Ã¥ unngÃ¥ feil i videre analyser

Den rensede dataen lagres i `data/clean/` som `.json` og inneholder Ã©n rad per dato, med enhetlige og ryddige kolonnenavn.

---

## ğŸ“Š `graph/` â€“ Visualisering (under utvikling)

Denne modulen er forelÃ¸pig under utvikling og vil bli utvidet i neste del av prosjektet. Her skal vi lage funksjoner for Ã¥ visualisere analyseresultatene pÃ¥ en ryddig og informativ mÃ¥te.

Planen er Ã¥ bruke biblioteker som:
- **matplotlib** og **seaborn** for klassiske statiske grafer
- **plotly** for interaktive grafer i Jupyter Notebook

Visualiseringene skal gjÃ¸re det lettere Ã¥:
- Se trender og variasjoner over tid
- Sammenligne ulike miljÃ¸parametere
- Formidle innsikt basert pÃ¥ de analyserte dataene

Funksjonene i denne mappen vil kunne importeres direkte i notebooken og brukes med rensede datasett.

---

## ğŸ“Œ Merk

- API-nÃ¸kler hÃ¥ndteres med `.env`-fil og `python-dotenv`
- RÃ¥data og renset data lagres i egne undermapper for sporbarhet
- Koden er strukturert for Ã¥ kunne gjenbrukes og testes senere i prosjektet

