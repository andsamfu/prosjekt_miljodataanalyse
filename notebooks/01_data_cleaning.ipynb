{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "517471da",
   "metadata": {},
   "source": [
    "# ğŸ§¼ Rensing og klargjÃ¸ring av data\n",
    "\n",
    "I denne notebooken klargjÃ¸r vi de innhentede datasettene fra NILU og Frost for videre analyse og visualisering.\n",
    "\n",
    "Vi utfÃ¸rer:\n",
    "- Strukturering av data\n",
    "- Fjerning av feil og outliers\n",
    "- Behandling av manglende verdier\n",
    "\n",
    "All renselogikk ligger i egne funksjoner og moduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665f2af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KjÃ¸r kode for Ã¥ rense data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed485a2d",
   "metadata": {},
   "source": [
    "## ğŸ§½ Om rensing og datakvalitet\n",
    "\n",
    "Etter at vi har hentet inn data fra Frost (MET) og NILU, er neste steg Ã¥ gjÃ¸re dataene klare til analyse. Dette handler bÃ¥de om Ã¥ forbedre kvaliteten pÃ¥ dataene â€“ og om Ã¥ vise at vi forstÃ¥r hvordan ulike datakilder stiller ulike krav til rensing.\n",
    "\n",
    "Vi valgte to datasett med kontrasterende egenskaper:\n",
    "\n",
    "- **Frost**: Strukturert, stabilt og nesten Â«analyseklartÂ»\n",
    "- **NILU**: Ujevnt, med mange manglende verdier og mÃ¥leutfordringer\n",
    "\n",
    "Denne kontrasten gir oss mulighet til Ã¥ vise bÃ¥de enkel validering og mer avansert rensing og imputasjon.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸŒ«ï¸ NILU â€“ utfordrende, men verdifullt\n",
    "\n",
    "Datasettet fra NILU inneholder daglige mÃ¥linger av luftkvalitet i Trondheim (PM10, PM2.5, NOâ‚‚), men er preget av:\n",
    "\n",
    "- Mange manglende verdier\n",
    "- Ekstreme mÃ¥linger og stÃ¸y\n",
    "- Ujevn dekning over tid og mellom komponenter\n",
    "\n",
    "Samtidig er dette realistiske utfordringer ved miljÃ¸data, og gir oss muligheten til Ã¥ vise god databehandling i praksis.\n",
    "\n",
    "#### ğŸ”§ Renseprosessen\n",
    "\n",
    "1. **Konvertering av datoer**  \n",
    "`dateTime` ble konvertert til `datetime`-format for Ã¥ gjÃ¸re videre tidsseriebehandling mulig (f.eks. resampling og glatting).\n",
    "\n",
    "2. **Pivotering av datastruktur**  \n",
    "MÃ¥lingene ble transformert slik at Ã©n rad tilsvarer Ã©n dag, og hver luftkomponent fikk sin egen kolonne. Dette forenkler all videre analyse.\n",
    "\n",
    "3. **Fjerning av kolonne**  \n",
    "`Benzo(a)pyrene in PM10` ble fjernet fordi den hadde nesten bare manglende verdier, og ikke er relevant for vÃ¥r problemstilling.\n",
    "\n",
    "4. **Fjerning av outliers**  \n",
    "MÃ¥linger som lÃ¥ mer enn 4 standardavvik fra gjennomsnittet ble fjernet. Disse kan vÃ¦re feil eller kortvarige, ekstreme hendelser som ikke representerer typiske forhold.\n",
    "\n",
    "5. **Reindeksering av datoer**  \n",
    "Alle datoer mellom fÃ¸rste og siste registrering ble inkludert, ogsÃ¥ de uten mÃ¥linger. Dette gjÃ¸r eventuelle datamangler synlige og muliggjÃ¸r presis imputasjon.\n",
    "\n",
    "6. **KNN-imputasjon (k = 100)**  \n",
    "Manglende verdier ble fylt inn med KNN-imputasjon, som bruker lignende dager til Ã¥ estimere manglende verdier. Mer om KNN-impulasjon og hvorfor vi har valgt dette kan du lese [her](KNN_imputation.ipynb)\n",
    "\n",
    "\n",
    "7. **Merking av estimerte verdier**  \n",
    "Vi opprettet egne `generated_*`-kolonner for Ã¥ vise hvilke verdier som er estimert. Dette gjÃ¸r datagrunnlaget transparent og analyserbart.\n",
    "\n",
    "8. **Glidende gjennomsnitt**  \n",
    "Vi brukte et 3-dagers glidende gjennomsnitt for Ã¥ jevne ut tilfeldige variasjoner og fremheve trender.  \n",
    "â€“ *Hvorfor?* Det gir mer lesbare grafer og et tydeligere bilde av utvikling, men uten Ã¥ skjule kortsiktige endringer.\n",
    "\n",
    "9. **Negative verdier satt til 0**  \n",
    "Luftforurensningsverdier kan ikke vÃ¦re negative. Disse feilene ble rettet for Ã¥ bevare datasettets troverdighet.\n",
    "\n",
    "10. **Lagring som JSON**  \n",
    "Renset data ble lagret som `.json`.  \n",
    "â€“ Lett Ã¥ lese og bruke videre i bÃ¥de analyse og visualisering.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸŒ¦ï¸ Frost â€“ strukturert, men fortsatt valideringsbehov\n",
    "\n",
    "Frost-dataene er langt mer komplette og standardiserte, men ble likevel validert og bearbeidet for Ã¥ sikre pÃ¥litelighet â€“ og for Ã¥ kunne kombineres med NILU.\n",
    "\n",
    "#### ğŸ”§ Renseprosessen\n",
    "\n",
    "1. **Konvertering av datoformat**  \n",
    "`referenceTime` ble formatert til datoobjekt for Ã¥ kunne brukes i tidsserier.\n",
    "\n",
    "2. **Utvalg av relevante variabler**  \n",
    "Vi fokuserte pÃ¥:\n",
    "  - Temperatur (gjennomsnitt per dag)\n",
    "  - NedbÃ¸r (total per dag)\n",
    "  - Vindhastighet (gjennomsnitt per dag)\n",
    "\n",
    "  Disse har dokumentert sammenheng med luftkvalitet. Andre mer usikre eller tekniske variabler ble utelatt.\n",
    "\n",
    "3. **Pivotering og navneendring**  \n",
    "Datasettet ble omstrukturert til Ã©n rad per dag med mer intuitive kolonnenavn.\n",
    "\n",
    "4. **Verdikontroll med `ValueRangeValidator`**  \n",
    "Vi definerte gyldige verdier for Trondheim:\n",
    "  - Temp: -30 til 40â€¯Â°C  \n",
    "  - NedbÃ¸r: 0 til 250â€¯mm  \n",
    "  - Vind: 0 til 60â€¯m/s  \n",
    "\n",
    "  Verdier utenfor ble fjernet â€“ de er trolig feilregistreringer.\n",
    "\n",
    "5. **Kontroll for dato-hull**  \n",
    "Med `DateContinuityValidator` sjekket vi at det ikke manglet perioder i tidsserien. SmÃ¥ hull ble registrert, men ikke imputert â€“ siden Frost generelt har god datadekning.\n",
    "\n",
    "6. **Lagring som SQLite**  \n",
    "VÃ¦rdataene ble lagret i en SQLite-database (`frost.db`) â€“ ideelt for videre analyse med SQL og for eventuell samkjÃ¸ring med stÃ¸rre datasett.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§  Hvorfor dette er en god tilnÃ¦rming\n",
    "\n",
    "Vi har valgt rensestrategier basert pÃ¥ datakildenes egenskaper:\n",
    "\n",
    "- **NILU** krevde:\n",
    "  - Komplett rekonstruering av datastrukturen\n",
    "  - Avansert imputasjon og glatting\n",
    "  - Transparens rundt hvilke verdier som er estimert\n",
    "\n",
    "- **Frost** krevde:\n",
    "  - Kontroll av gyldige verdier og datoer\n",
    "  - Lett justering og tilrettelegging for videre analyse\n",
    "\n",
    "Dette viser:\n",
    "- ForstÃ¥else av hva som pÃ¥virker datakvalitet\n",
    "- Evne til Ã¥ tilpasse metoder etter utfordring\n",
    "- Fokus pÃ¥ transparens og sporbarhet\n",
    "\n",
    "Resultatet er et datasett som bÃ¥de er **ryddet og dokumentert**, og klart for videre analyse, visualisering og modellering.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ˆ Neste steg: Analyse og visualisering\n",
    "\n",
    "NÃ¥ som begge datasett er renset og klargjort, er vi klare for Ã¥ utforske innholdet mer inngÃ¥ende. I neste notebook skal vi:\n",
    "\n",
    "- Beregne statistiske mÃ¥l som gjennomsnitt, median og standardavvik\n",
    "- UndersÃ¸ke sammenhenger og trender i luftkvalitet og vÃ¦rdata over tid\n",
    "- Lage visuelle fremstillinger som gjÃ¸r datamÃ¸nstre lettere Ã¥ forstÃ¥\n",
    "\n",
    "\n",
    "### [**Videre til analyse og visualisering**](02_data_analysis_and_visualisation.ipynb)\n",
    "##### [**Til samlesiden**](../docs/samleside.md)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
