{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "517471da",
   "metadata": {},
   "source": [
    "# 🧼 Rensing og klargjøring av data\n",
    "\n",
    "I denne notebooken klargjør vi de innhentede datasettene fra NILU og Frost for videre analyse og visualisering.\n",
    "\n",
    "Vi utfører:\n",
    "- Strukturering av data\n",
    "- Fjerning av feil og outliers\n",
    "- Behandling av manglende verdier\n",
    "\n",
    "All renselogikk ligger i egne funksjoner og moduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665f2af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kjør kode for å rense data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed485a2d",
   "metadata": {},
   "source": [
    "## 🧽 Om rensing og datakvalitet\n",
    "\n",
    "Etter at vi har hentet inn data fra Frost (MET) og NILU, er neste steg å gjøre dataene klare til analyse. Dette handler både om å forbedre kvaliteten på dataene – og om å vise at vi forstår hvordan ulike datakilder stiller ulike krav til rensing.\n",
    "\n",
    "Vi valgte to datasett med kontrasterende egenskaper:\n",
    "\n",
    "- **Frost**: Strukturert, stabilt og nesten «analyseklart»\n",
    "- **NILU**: Ujevnt, med mange manglende verdier og måleutfordringer\n",
    "\n",
    "Denne kontrasten gir oss mulighet til å vise både enkel validering og mer avansert rensing og imputasjon.\n",
    "\n",
    "---\n",
    "\n",
    "### 🌫️ NILU – utfordrende, men verdifullt\n",
    "\n",
    "Datasettet fra NILU inneholder daglige målinger av luftkvalitet i Trondheim (PM10, PM2.5, NO₂), men er preget av:\n",
    "\n",
    "- Mange manglende verdier\n",
    "- Ekstreme målinger og støy\n",
    "- Ujevn dekning over tid og mellom komponenter\n",
    "\n",
    "Samtidig er dette realistiske utfordringer ved miljødata, og gir oss muligheten til å vise god databehandling i praksis.\n",
    "\n",
    "#### 🔧 Renseprosessen\n",
    "\n",
    "1. **Konvertering av datoer**  \n",
    "`dateTime` ble konvertert til `datetime`-format for å gjøre videre tidsseriebehandling mulig (f.eks. resampling og glatting).\n",
    "\n",
    "2. **Pivotering av datastruktur**  \n",
    "Målingene ble transformert slik at én rad tilsvarer én dag, og hver luftkomponent fikk sin egen kolonne. Dette forenkler all videre analyse.\n",
    "\n",
    "3. **Fjerning av kolonne**  \n",
    "`Benzo(a)pyrene in PM10` ble fjernet fordi den hadde nesten bare manglende verdier, og ikke er relevant for vår problemstilling.\n",
    "\n",
    "4. **Fjerning av outliers**  \n",
    "Målinger som lå mer enn 4 standardavvik fra gjennomsnittet ble fjernet. Disse kan være feil eller kortvarige, ekstreme hendelser som ikke representerer typiske forhold.\n",
    "\n",
    "5. **Reindeksering av datoer**  \n",
    "Alle datoer mellom første og siste registrering ble inkludert, også de uten målinger. Dette gjør eventuelle datamangler synlige og muliggjør presis imputasjon.\n",
    "\n",
    "6. **KNN-imputasjon (k = 100)**  \n",
    "Manglende verdier ble fylt inn med KNN-imputasjon, som bruker lignende dager til å estimere manglende verdier. Mer om KNN-impulasjon og hvorfor vi har valgt dette kan du lese [her](KNN_imputation.ipynb)\n",
    "\n",
    "\n",
    "7. **Merking av estimerte verdier**  \n",
    "Vi opprettet egne `generated_*`-kolonner for å vise hvilke verdier som er estimert. Dette gjør datagrunnlaget transparent og analyserbart.\n",
    "\n",
    "8. **Glidende gjennomsnitt**  \n",
    "Vi brukte et 3-dagers glidende gjennomsnitt for å jevne ut tilfeldige variasjoner og fremheve trender.  \n",
    "– *Hvorfor?* Det gir mer lesbare grafer og et tydeligere bilde av utvikling, men uten å skjule kortsiktige endringer.\n",
    "\n",
    "9. **Negative verdier satt til 0**  \n",
    "Luftforurensningsverdier kan ikke være negative. Disse feilene ble rettet for å bevare datasettets troverdighet.\n",
    "\n",
    "10. **Lagring som JSON**  \n",
    "Renset data ble lagret som `.json`.  \n",
    "– Lett å lese og bruke videre i både analyse og visualisering.\n",
    "\n",
    "---\n",
    "\n",
    "### 🌦️ Frost – strukturert, men fortsatt valideringsbehov\n",
    "\n",
    "Frost-dataene er langt mer komplette og standardiserte, men ble likevel validert og bearbeidet for å sikre pålitelighet – og for å kunne kombineres med NILU.\n",
    "\n",
    "#### 🔧 Renseprosessen\n",
    "\n",
    "1. **Konvertering av datoformat**  \n",
    "`referenceTime` ble formatert til datoobjekt for å kunne brukes i tidsserier.\n",
    "\n",
    "2. **Utvalg av relevante variabler**  \n",
    "Vi fokuserte på:\n",
    "  - Temperatur (gjennomsnitt per dag)\n",
    "  - Nedbør (total per dag)\n",
    "  - Vindhastighet (gjennomsnitt per dag)\n",
    "\n",
    "  Disse har dokumentert sammenheng med luftkvalitet. Andre mer usikre eller tekniske variabler ble utelatt.\n",
    "\n",
    "3. **Pivotering og navneendring**  \n",
    "Datasettet ble omstrukturert til én rad per dag med mer intuitive kolonnenavn.\n",
    "\n",
    "4. **Verdikontroll med `ValueRangeValidator`**  \n",
    "Vi definerte gyldige verdier for Trondheim:\n",
    "  - Temp: -30 til 40 °C  \n",
    "  - Nedbør: 0 til 250 mm  \n",
    "  - Vind: 0 til 60 m/s  \n",
    "\n",
    "  Verdier utenfor ble fjernet – de er trolig feilregistreringer.\n",
    "\n",
    "5. **Kontroll for dato-hull**  \n",
    "Med `DateContinuityValidator` sjekket vi at det ikke manglet perioder i tidsserien. Små hull ble registrert, men ikke imputert – siden Frost generelt har god datadekning.\n",
    "\n",
    "6. **Lagring som SQLite**  \n",
    "Værdataene ble lagret i en SQLite-database (`frost.db`) – ideelt for videre analyse med SQL og for eventuell samkjøring med større datasett.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Hvorfor dette er en god tilnærming\n",
    "\n",
    "Vi har valgt rensestrategier basert på datakildenes egenskaper:\n",
    "\n",
    "- **NILU** krevde:\n",
    "  - Komplett rekonstruering av datastrukturen\n",
    "  - Avansert imputasjon og glatting\n",
    "  - Transparens rundt hvilke verdier som er estimert\n",
    "\n",
    "- **Frost** krevde:\n",
    "  - Kontroll av gyldige verdier og datoer\n",
    "  - Lett justering og tilrettelegging for videre analyse\n",
    "\n",
    "Dette viser:\n",
    "- Forståelse av hva som påvirker datakvalitet\n",
    "- Evne til å tilpasse metoder etter utfordring\n",
    "- Fokus på transparens og sporbarhet\n",
    "\n",
    "Resultatet er et datasett som både er **ryddet og dokumentert**, og klart for videre analyse, visualisering og modellering.\n",
    "\n",
    "---\n",
    "\n",
    "## 📈 Neste steg: Analyse og visualisering\n",
    "\n",
    "Nå som begge datasett er renset og klargjort, er vi klare for å utforske innholdet mer inngående. I neste notebook skal vi:\n",
    "\n",
    "- Beregne statistiske mål som gjennomsnitt, median og standardavvik\n",
    "- Undersøke sammenhenger og trender i luftkvalitet og værdata over tid\n",
    "- Lage visuelle fremstillinger som gjør datamønstre lettere å forstå\n",
    "\n",
    "\n",
    "### [**Videre til analyse og visualisering**](02_data_analysis_and_visualisation.ipynb)\n",
    "##### [**Til samlesiden**](../docs/samleside.md)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
