{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64a2cc64",
   "metadata": {},
   "source": [
    "# 🌿 Miljødataanalyse – Prosjektoversikt og initiering\n",
    "\n",
    "Denne notebooken fungerer som startpunktet for prosjektet og gir en oversikt over hvilke datakilder vi har valgt, hvorfor vi har valgt dem, og hvordan vi henter inn data på en sikker og strukturert måte.\n",
    "\n",
    "All funksjonell kode er samlet i `src/`-mappen for å holde notebookene ryddige og oversiktlige. Vi importerer kun nødvendige funksjoner i toppen av hver notebook for å gjøre arbeidsflyten lett å følge og vedlikeholde.\n",
    "\n",
    "### 🔐 Sikker håndtering av API-nøkkel\n",
    "\n",
    "For å hente værdata fra Frost API kreves det en personlig API-nøkkel. For å beskytte denne har vi lagret nøkkelen i en `.env`-fil, og lagt den til i `.gitignore`. Dette sikrer at nøkkelen ikke inkluderes i versjonskontrollen, selv om prosjektet deles offentlig. På denne måten unngår vi misbruk og følger god praksis for håndtering av sensitive opplysninger.\n",
    "\n",
    "\n",
    "Under finner du en oversikt over hvilke datakilder vi henter informasjon fra, og hvorfor vi har valgt nettopp disse.\n",
    "\n",
    "\n",
    "## 🌐 Valg og implementering av datakilder\n",
    "\n",
    "For å kunne gjennomføre en relevant og innsiktsfull miljødataanalyse har vi valgt å hente data fra to åpne, norske API-er som tilbyr pålitelige og relevante miljømålinger: Meteorologisk institutt (MET) og Norsk institutt for luftforskning (NILU). Disse gir oss både bredde og dybde i datagrunnlaget, og åpner for ulike faglige utfordringer og muligheter i prosjektet.\n",
    "\n",
    "---\n",
    "\n",
    "### 🌦️ Værdata – Frost API fra MET\n",
    "\n",
    "Værdataene hentes fra [Frost API](https://frost.met.no/) levert av Meteorologisk institutt (MET). Dette API-et gir strukturert tilgang til historiske værdata fra offisielle målestasjoner i hele Norge.\n",
    "\n",
    "Vi valgte Frost fordi:\n",
    "- Det er en **offentlig og anerkjent datakilde** med høy faglig og teknisk kvalitet\n",
    "- Vi får tilgang til **daglig målinger** av variabler som temperatur, nedbør og vind\n",
    "- Spørringer kan tilpasses presist via koordinater og datoperiode\n",
    "- Dataene returneres i **standardisert JSON-format**, som er enkelt å behandle videre i Python\n",
    "\n",
    "For å hente og strukturere dataene har vi utviklet klassen `WeatherDataFetcher`. Den:\n",
    "- Henter nærmeste målestasjon basert på brukerens koordinater\n",
    "- Henter værdata fra denne stasjonen over en definert tidsperiode\n",
    "- Bruker `pandas` og `pandasql` til å strukturere dataene\n",
    "- Lagrer resultatet i en SQLite-database for videre analyser og prediktiv modellering\n",
    "\n",
    "Dataen vi henter:\n",
    "- Gjennomsnitts **temperatur** per døgn (float)\n",
    "- Gjennomsnitts **vindhastighet** per døgn (float)\n",
    "- Total **nedbørsmengde** per døgn (float)\n",
    "\n",
    "Dette gir oss et fleksibelt og robust system som enkelt kan gjenbrukes for ulike lokasjoner og perioder.\n",
    "\n",
    "---\n",
    "\n",
    "### 🏭 Luftkvalitet – NILU API\n",
    "\n",
    "Luftkvalitetsdataene hentes fra [NILUs API](https://api.nilu.no/), utviklet av Norsk institutt for luftforskning. API-et gir tilgang til målinger av luftforurensning (PM10, PM2.5, NO₂ m.m.) fra stasjoner over hele landet, inkludert Trondheim.\n",
    "\n",
    "Vi valgte NILU fordi:\n",
    "- Det er en **offentlig og anerkjent datakilde** på luftforurensning i Norge\n",
    "- Dataene er **gratis og tilgjengelige uten API-nøkkel**\n",
    "- API-et returnerer data i **JSON-format**, og støtter søk basert på sted, tid og radius\n",
    "- Datasettet gir oss innsikt i **lokale miljøutfordringer**, spesielt knyttet til luftkvalitet i byområder\n",
    "\n",
    "Vi har laget klassen `AirQualityDataFetcher`, som:\n",
    "- Henter historiske målinger for et gitt område og periode\n",
    "- Lagrer resultatet som en `.json`-fil i `data/raw/`\n",
    "- Forbereder datasettet for videre rensing og analyse\n",
    "\n",
    "Dataen vi henter:\n",
    "- Daglig måling av **NO2** konsentrasjon (float)\n",
    "- Daglig måling av **PM2.5** konsentrasjon (float)\n",
    "- Daglig måling av **PM10** konsentrasjon (float)\n",
    "\n",
    "\n",
    "#### 🎯 Hvorfor vi aktivt valgte et mer utfordrende datasett\n",
    "\n",
    "I motsetning til Frost-dataene er NILU-datasettet ofte preget av manglende verdier, varierende målefrekvens og ujevn datadekning. Dette var en bevisst beslutning, nettopp fordi det gir oss en verdifull mulighet til å demonstrere kunnskap om:\n",
    "\n",
    "- Hvordan man **oppdager og håndterer manglende eller ustrukturerte data**\n",
    "- Hvilke konsekvenser rensing og filtrering har for datakvalitet og tolkning\n",
    "- Hvordan ulike valg under rensing påvirker både visualisering og videre analyse\n",
    "\n",
    "Ved å inkludere et datasett med lavere kvalitet får vi vist hvordan datarensing ikke bare er et teknisk steg, men en viktig faglig vurdering med betydning for resultatene.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Relevans for vurderingskriteriene\n",
    "\n",
    "Valgene våre er i tråd med vurderingskriteriene i oppgave 2:\n",
    "\n",
    "- Vi har identifisert og begrunnet bruken av **to åpne, relevante og autoritative datakilder**\n",
    "- Vi har vurdert **kvalitet, tilgjengelighet og struktur** i begge datasettene\n",
    "- Vi har laget egne Python-klasser for datainnhenting, med bruk av `requests`, `dotenv`, `pandas` og `pandasql`\n",
    "- Vi har aktivt valgt å jobbe med **et krevende datasett** for å synliggjøre forståelse av databehandling og datakvalitet\n",
    "\n",
    "Dette gir et solid grunnlag for resten av prosjektet – både teknisk og faglig – og legger til rette for videre rensing, analyse, visualisering og prediktiv modellering.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔄 Neste steg: Rensing og klargjøring av data\n",
    "\n",
    "Etter at dataene er hentet inn fra Frost og NILU, inneholder de både nyttig informasjon og noen utfordringer – spesielt når det gjelder format, manglende verdier og ujevn datakvalitet.\n",
    "\n",
    "I neste notebook ser vi nærmere på hvordan vi har valgt å:\n",
    "- strukturere og forenkle dataene\n",
    "- håndtere manglende verdier og uregelmessigheter\n",
    "- forberede datasettet for videre analyse og visualisering\n",
    "\n",
    "### [**Videre til datarensing**](01_data_cleaning.ipynb)\n",
    "##### [**Til samlesiden**](../docs/samleside.md)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
